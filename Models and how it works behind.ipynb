{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208,
     "referenced_widgets": [
      "effe53f7aa7e4e4c9b7e7f32319b5cd9",
      "7cfea87cc977479c83e138e170ff4302",
      "ba3b0bfad77c4a06b6034c05738c4aa8",
      "7416effef58a41e3833a36fd22697398",
      "eed4cf7a86f54522ae6e95eb6986ed3f",
      "77b4a174059c4e63891d412d93f688d1",
      "734c5a38f79842f7af7334a7739c5534",
      "07ead9b083ac4197a7eb4fa2fadbc640",
      "1b9205b58d8645f68d535d45246c4cee",
      "3ee6b7df057046f691a11502b52ba2f2",
      "017a0b59e84a4c3bad4ba9927018cb8e",
      "0de16f54dd864944b49372c44b7f880a",
      "7b8328084a574914b65b07805f189056",
      "45c17ef7d1c34a619e86bc619aad4829",
      "6c4374bc61d44bbaaf6b86384f4a89bb",
      "3da61c14f0c54527a512bdb01e87f764",
      "9d991487f0784bdcbfd9b82726e6653d",
      "e3673ec1dda341d5b5d7e9b3dca3f64a",
      "ef9da89720504a98b05e4b357d9086eb",
      "b66e44615d7c42ba8b10467b24fca2dc",
      "d6f0a485fbc240a1806d5a23cec50288",
      "56e9ad7a65504a51a6aa0628e84025bc"
     ]
    },
    "executionInfo": {
     "elapsed": 54314,
     "status": "ok",
     "timestamp": 1750749919763,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "kwd1DX2Lv7bP",
    "outputId": "67603b2b-f282-4b3d-8a5d-7e2af627d259"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "effe53f7aa7e4e4c9b7e7f32319b5cd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de16f54dd864944b49372c44b7f880a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"bert-base-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 2612,
     "status": "ok",
     "timestamp": 1750750161578,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "ohrA0aFl0sSV"
   },
   "outputs": [],
   "source": [
    "model.save_pretrained(\"/content/directory_on_my_computer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 114,
     "status": "ok",
     "timestamp": 1750750240220,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "3WJoMHA81upP",
    "outputId": "72885aa3-6b8f-4c50-f9d4-f8cd8cc79ba4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config.json  model.safetensors\n"
     ]
    }
   ],
   "source": [
    "ls /content/directory_on_my_computer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 230,
     "status": "ok",
     "timestamp": 1750750447915,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "-GaWuV4J1yob",
    "outputId": "d6dae35a-764c-44b2-cfde-744c46ca40e2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To reuse a saved model, use the from_pretrained() method again:\n",
    "from transformers import AutoModel\n",
    "\n",
    "model = AutoModel.from_pretrained(\"/content/directory_on_my_computer\")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17,
     "referenced_widgets": [
      "3670ba266f424e8a99ede0c334f611c3",
      "aecb3266ffe940ca9af9b1a2a3558a7c",
      "fce7067d8b82456580293d5d9d028d77",
      "d3db5f20d34843f1918f8b500bbb8b4b",
      "3f4bc9ef22a04ad29c4ef15c5e88b06e",
      "e1f13b6a632b46959e3ab47002560a82",
      "6d8c15bdd96a4215a47c1de9133e879d",
      "5bed8ded485d42868c3445e8f661f1b3",
      "aa2b46886d7a416eb04026a884375390",
      "2d907399e643482bb46be63f18792415",
      "9b9b2fe259234d0b809486631feb6c88",
      "e8030bd3229e46bbbb88527f0530d501",
      "72485391fd214bd4b61047364540d782",
      "490c84e462f549d19f9265662e4a89be",
      "9ed24ecfe6a84e33a5ec0949e634fb82",
      "a5cae706217a4c53a3b1db3f80a5f2ba",
      "14ca42c96b6241f98c3b11939c0dc2c0",
      "c85663aec31d44878224ccf430ad618e",
      "21effca0050e4aa7a2111fb79cfbbff7",
      "88ea50c0c8b44b7c90ed9482d1bcdaf9"
     ]
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1750750488601,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "IytknoHD27DU",
    "outputId": "83fe31e7-b6f4-4dfb-aadf-a3af81d95b16"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3670ba266f424e8a99ede0c334f611c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1750751082642,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "ldhagARY3GYu"
   },
   "outputs": [],
   "source": [
    "# Transformer models handle text by turning the inputs into numbers. Here we will look at exactly what happens when your text is\n",
    "# processed by the tokenizer. We’ve already seen in Chapter 1 that tokenizers split the text into tokens and then convert\n",
    "# these tokens into numbers. We can see this conversion through a simple tokenizer:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1750751181968,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "18iYLkGu5Xc5",
    "outputId": "c92bf5da-a2f6-4ba6-fe42-d8f7f4ab6a37"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 8667, 117, 146, 112, 182, 170, 1423, 5650, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "encoded_input = tokenizer(\"Hello, I'm a single sentence!\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1750751422521,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "RBR3fPtH5m3t",
    "outputId": "b4e545f3-0911-4fc5-bba8-a82bd7adda04"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 8667, 117, 146, 112, 182, 170, 1423, 5650, 106, 102]\n",
      "[CLS] Hello, I ' m a single sentence! [SEP]\n"
     ]
    }
   ],
   "source": [
    "# You’ll notice that the tokenizer has added special tokens — [CLS] and [SEP] — required by the model.\n",
    "#  Not all models need special tokens; they’re utilized when a model was pretrained with them,\n",
    "#  in which case the tokenizer needs to add them as that model expects these tokens.\n",
    "a=encoded_input[\"input_ids\"]\n",
    "print(a) #numerical representations of your tokens\n",
    "b=tokenizer.decode(encoded_input[\"input_ids\"])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750751477014,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "JgTJEEWx58OR",
    "outputId": "dfb9b5ab-8771-4efd-985a-17a101884552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]\n"
     ]
    }
   ],
   "source": [
    "a=encoded_input[\"token_type_ids\"]\n",
    "print(a) #these tell the model which part of the input is sentence A and which is sentence B\n",
    "b=b=tokenizer.decode(encoded_input[\"token_type_ids\"])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750751520592,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "RK5_xD9w6CKH",
    "outputId": "73a85b03-e86e-44d9-8ce6-2b61038a5994"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1] [unused1]\n"
     ]
    }
   ],
   "source": [
    "a=encoded_input[\"attention_mask\"] #this indicates which tokens should be attended to and which should not\n",
    "print(a)\n",
    "b=tokenizer.decode(encoded_input[\"attention_mask\"])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1750751770576,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "bTzcWd5B6Fz_",
    "outputId": "a6f385c8-428d-4017-e891-803775fc9eb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [101, 1731, 1132, 1128, 136, 102, 146, 112, 182, 2503, 117, 6243, 1128, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "# You can encode multiple sentences at once, either by batching them together (we’ll discuss this soon) or by passing a list:\n",
    "encoded_input = tokenizer(\"How are you?\", \"I'm fine, thank you!\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 61,
     "status": "ok",
     "timestamp": 1750756795004,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "0IzgdJAD70tZ",
    "outputId": "64328588-1d62-4918-95fe-f9b0b8708d64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[ 101, 8667,  117,  146,  112,  182,  170, 1423, 5650,  106,  102]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that when passing multiple sentences, the tokenizer returns a list for each sentence for each dictionary value.\n",
    "# We can also ask the tokenizer to return tensors directly from PyTorch:\n",
    "encoded_input_tensor = tokenizer(\"Hello, I'm a single sentence!\",return_tensors='pt')\n",
    "\n",
    "encoded_input_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1750756931608,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "dsjuOGDBPJFI"
   },
   "outputs": [],
   "source": [
    "# But there’s a problem: the two lists don’t have the same length!\n",
    "# Arrays and tensors need to be rectangular, so we can’t simply convert these lists to a PyTorch tensor (or NumPy array).\n",
    "# The tokenizer provides an option for that: padding.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1750757136615,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "ERCBBNq4PrbI",
    "outputId": "044b86b7-d0ee-4af6-8e25-3fa3b0cf9365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:     tensor([[ 101, 1731, 1132, 1128,  136,  102,    0,    0,    0,    0],\n",
      "        [ 101,  146,  112,  182, 2503,  117, 6243, 1128,  106,  102]]) \n",
      "\n",
      "token_type_ids:     tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]) \n",
      "\n",
      "attention_mask:     tensor([[1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Padding inputs\n",
    "# If we ask the tokenizer to pad the inputs, it will make all sentences the same length by adding a\n",
    "# special padding token to the sentences that are shorter than the longest one:\n",
    "\n",
    "encoded_input = tokenizer(\n",
    "    [\"How are you?\", \"I'm fine, thank you!\"], padding=True, return_tensors=\"pt\"\n",
    ")\n",
    "# print(encoded_input)\n",
    "print(\"input_ids:    \",    encoded_input[\"input_ids\"],('\\n'))\n",
    "print(\"token_type_ids:    \",encoded_input[\"token_type_ids\"],('\\n'))\n",
    "print(\"attention_mask:    \",encoded_input[\"attention_mask\"],('\\n'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1750757197158,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "QWgi7ZzzPvl-"
   },
   "outputs": [],
   "source": [
    "# Now we have rectangular tensors! Note that the padding tokens have been encoded into input IDs with ID 0, and\n",
    "# they have an attention mask value of 0 as well.\n",
    "# This is because those padding tokens shouldn’t be analyzed by the model: they’re not part of the actual sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1750757215922,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "Swot1wpxQsQe"
   },
   "outputs": [],
   "source": [
    "# Truncating inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1750758114285,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "MOQOTzqEQvP3",
    "outputId": "ed11fafd-0b4e-430a-9ac0-ec1fed867ef3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1188, 1110, 170, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1263, 5650, 119, 102]\n"
     ]
    }
   ],
   "source": [
    "# The tensors might get too big to be processed by the model. For instance, BERT was only pretrained with sequences up to 512 tokens,\n",
    "# so it cannot process longer sequences.\n",
    "# If you have sequences longer than the model can handle, you’ll need to truncate them with the truncation parameter:\n",
    "\n",
    "encoded_input = tokenizer(\n",
    "    \"This is a very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very very long sentence.\",\n",
    "    truncation=True,\n",
    ")\n",
    "print(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1750758008486,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "XFxsVh2pTn1O"
   },
   "outputs": [],
   "source": [
    "a=[101, 1188, 1110, 170, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304,\n",
    " 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304,\n",
    " 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304,\n",
    " 1304, 1304, 1304, 1304, 1304, 1263, 5650, 119, 102]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1750758013111,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "e5pvk5AxTwVf",
    "outputId": "1779a4c0-3dcc-44f3-9445-ff5a24832180"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1750758122767,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "TzvtT3vXTzbN",
    "outputId": "5654595c-fc26-4560-fc19-b3bcb4c5c101"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b=[101, 1188, 1110, 170, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1304, 1263, 5650, 119, 102]\n",
    "\n",
    "\n",
    "len(b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1750758227518,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "vVYrVBYET4TK",
    "outputId": "5b5a65cb-b7ce-4725-eb66-7a99a74ca857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids:     tensor([[ 101, 1731, 1132, 1128,  102],\n",
      "        [ 101,  146,  112,  182,  102]]) \n",
      "\n",
      "token_type_ids:     tensor([[0, 0, 0, 0, 0],\n",
      "        [0, 0, 0, 0, 0]]) \n",
      "\n",
      "attention_mask:     tensor([[1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoded_input = tokenizer(\n",
    "    [\"How are you?\", \"I'm fine, thank you!\"],\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=5,\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "# print(encoded_input)\n",
    "print(\"input_ids:    \",    encoded_input[\"input_ids\"],('\\n'))\n",
    "print(\"token_type_ids:    \",encoded_input[\"token_type_ids\"],('\\n'))\n",
    "print(\"attention_mask:    \",encoded_input[\"attention_mask\"],('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 37,
     "status": "ok",
     "timestamp": 1750758351626,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "Kg9fnHcvUg6w"
   },
   "outputs": [],
   "source": [
    "# # Adding special tokens\n",
    "# Special tokens (or at least the concept of them) is particularly important to BERT and derived models.\n",
    "# These tokens are added to better represent the sentence boundaries,\n",
    "# such as the beginning of a sentence ([CLS]) or separator between sentences ([SEP]). Let’s look at a simple example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "executionInfo": {
     "elapsed": 52,
     "status": "ok",
     "timestamp": 1750758379439,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "AiHTIlzvVGGY",
    "outputId": "2b66ce7b-d05f-4daa-aa2d-b76397fc62ff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101, 1731, 1132, 1128, 136, 102]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'[CLS] How are you? [SEP]'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(\"How are you?\")\n",
    "print(encoded_input[\"input_ids\"])\n",
    "tokenizer.decode(encoded_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "executionInfo": {
     "elapsed": 44,
     "status": "ok",
     "timestamp": 1750758895174,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "HcA5vw2VVLnZ"
   },
   "outputs": [],
   "source": [
    "#-------------- Why is all of this necessary?   🧪 Goal: Feed raw text to a model and get the output-------------------------------------------\n",
    "\n",
    "sequences = [\n",
    "    \"I've been waiting for a HuggingFace course my whole life.\",\n",
    "    \"I hate this so much!\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "executionInfo": {
     "elapsed": 43,
     "status": "ok",
     "timestamp": 1750758940854,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "wAhQTd62VjY7"
   },
   "outputs": [],
   "source": [
    "# Step 1:\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 177,
     "referenced_widgets": [
      "0e90d10f78884f3583a0f65d9586a4a7",
      "207e3f4fdf2342048b9f8bc1452acf34",
      "b87a56b5605948ed9325ec95c2568697",
      "78542a5e36dc4f7ab4cb58accfbe897a",
      "dac9de3c319b42ddac654ac0cd58dd9e",
      "ac6f7db1f3334de6940dd76ae8594def",
      "40fc47ec41394490a307ffc1ae2b0d82",
      "4d7a93c38737432db31319f83bcd086b",
      "c47b82573b4541deabe863db9fc65e7a",
      "c8f537888ff641a8b29d17d94e8c0dc2",
      "8b39dde752f546fe9aacdb725bf2b689",
      "d282851ad75f41b296710de35b097c45",
      "67e37a66bb234c9fbde14b8a2a3dc408",
      "30aeb2f06c1346de824d0abbbcf3cf82",
      "d33df2f83f004d4597652d52bceb3d53",
      "177d5bbf41634108912a1cb5f32f5a1f",
      "9ef0a29dd2134e9a8f00c44d213b7b91",
      "849cd0b7d0314bd685b2a254445348ec",
      "f8d063cb97114ed791c41e665406f5b2",
      "dafec68b7d604af98c22436501966e0a",
      "189981de38904d2fbe781d2896a25d09",
      "1a263721155541b8a570c8345e794691",
      "938c0c797da84dfc9f333288397c2b23",
      "a2ee38b766a24e128343cccc10f8b38e",
      "305d5940edce43e79494ddd4717b997c",
      "4519494355db4d44a10ba542d68bd83c",
      "89ec92bb6c1149d6a522b5c9a06a8c33",
      "815acb6c8b6c438f95fd0196567513cd",
      "232a478586514e32b5bdd0d022284a2a",
      "c14649ba94584f8fadb00f0cca345f5d",
      "8fe19cc14405474fb9695e1dd652e0da",
      "616b128659aa4d8cacbb755e6e7d3287",
      "bb46dbe6227441a49af4d38fcb79219a",
      "0a4aa521c2174fa88aebaee27146d224",
      "c6a0fef1079b45a1bbe07d862a519304",
      "9814caac07f241b58254a978f19513a3",
      "da76b7866c3e477193283b6b1f13e728",
      "7cc0bf91dbc1472aa86c1bab587e8020",
      "4df41c784da74a30807c871e3c161242",
      "23e038b0bfb04f0ca703650d521c5112",
      "4a0215949d334fa99ed969107c9e3b30",
      "d8a28067b481404983001d83f1a66805",
      "31058a0a768449d8bdf18fd95d60580e",
      "b2327f0af9da4c94a477f6e5db9754d2",
      "79ba16c6a85f4b719b222c939556809e",
      "477314d4804d4307b4dec71b7fe9e62b",
      "72102b0879aa48faaeb4da878f3713eb",
      "460220ea201e4852b450d0d1fec97f1c",
      "6806b34edf164846a5a1591538c2c054",
      "daaceacd1cf0404786f851704f82316a",
      "a46c5df65cd846699a6a97a7a8d8a1af",
      "9d8fbab82cbf4b149fbc18d3f4af70e0",
      "d81115ca53ee47229534006044120420",
      "f00644cf31ef425789710bafbec16097",
      "61ca6dd5d59245e1aaf56637c5f0952b"
     ]
    },
    "executionInfo": {
     "elapsed": 6774,
     "status": "ok",
     "timestamp": 1750759012314,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "TAHf_OkCVq2e",
    "outputId": "37a69b1b-0d61-42ff-9cc1-21d872adce02"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e90d10f78884f3583a0f65d9586a4a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d282851ad75f41b296710de35b097c45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938c0c797da84dfc9f333288397c2b23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4aa521c2174fa88aebaee27146d224",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ba16c6a85f4b719b222c939556809e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Step 2: Load tokenizer and model\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1750759093135,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "IRVacF9cVs4U",
    "outputId": "b281923d-38ef-4afa-e623-7321d4e0d7be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[ 101, 1045, 5223, 2023, 2061, 2172,  999,  102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Tokenize the input sentence\n",
    "\n",
    "# 101: special [CLS] token\n",
    "\n",
    "# 102: special [SEP] token\n",
    "\n",
    "# Numbers in between are token IDs from tokenizer’s vocabulary.\n",
    "\n",
    "# attention_mask tells the model which tokens to focus on (1) or ignore (0 for padding).\n",
    "\n",
    "\n",
    "sentence = \"I hate this so much!\"\n",
    "encoded_input = tokenizer(sentence, return_tensors=\"pt\")\n",
    "print(encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "executionInfo": {
     "elapsed": 293,
     "status": "ok",
     "timestamp": 1750759118661,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "HiliG8xkV3iM"
   },
   "outputs": [],
   "source": [
    "# Step 4: Feed tokenized input to the model\n",
    "with torch.no_grad():  # no need to compute gradients for inference\n",
    "    outputs = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1750759214369,
     "user": {
      "displayName": "Shivani Moze",
      "userId": "12558247643904706409"
     },
     "user_tz": -330
    },
    "id": "6_KgQH06YBTO",
    "outputId": "e3491a2a-9122-4db6-8993-50c36286b9ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 8, 768])\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Check the output\n",
    "print(outputs.last_hidden_state.shape)     #outputs.last_hidden_state is a matrix of shape [batch_size, sequence_length, hidden_size]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xsAcS3Y0YHff"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMvb5uTBuCRPbrJholmrTz6",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
